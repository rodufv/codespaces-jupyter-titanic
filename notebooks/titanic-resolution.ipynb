{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "# import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados de treino e teste\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "Valores nulos no conjunto de treino:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "Valores nulos no conjunto de teste:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificando estatísticas descritivas e valores nulos\n",
    "train_statistics = train_data.describe()\n",
    "print(train_data.info())\n",
    "print(\"Valores nulos no conjunto de treino:\\n\", train_data.isnull().sum())\n",
    "print(\"Valores nulos no conjunto de teste:\\n\", test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando funções para processamento de dados\n",
    "def preprocess_data(data):\n",
    "    # Mapeando valores categóricos para numéricos\n",
    "    data['IsFemale'] = data['Sex'].map({'female': 1, 'male': 0})\n",
    "    \n",
    "    # Preenchendo valores nulos em 'Fare', 'Age' e 'Embarked'\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].mean())\n",
    "    data['Age'] = data['Age'].fillna(data['Age'].mean())\n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "    \n",
    "    # Mapeando valores categóricos de 'Embarked' para numéricos\n",
    "    data['Port'] = data['Embarked'].map({'S': 1, 'C': 2, 'Q': 3})\n",
    "    \n",
    "    # Criando a feature 'Child'\n",
    "    data['Child'] = np.where(data['Age'] < 12, 1, 0)\n",
    "\n",
    "    # Tamanho da Família\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "    # Titulo do passageiro\n",
    "    # title_mapping = {\n",
    "    #     \"Mr\": \"Mr\",\n",
    "    #     \"Miss\": \"Miss\",\n",
    "    #     \"Mrs\": \"Mrs\",\n",
    "    #     \"Master\": \"Master\",\n",
    "    #     \"Dr\": \"Dr\",\n",
    "    #     \"Rev\": \"Rev\",\n",
    "    #     \"Col\": \"Col\",\n",
    "    #     \"Major\": \"Major\",\n",
    "    #     \"Mlle\": \"Miss\",\n",
    "    #     \"Mme\": \"Mrs\"\n",
    "    # }\n",
    "    # data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.')\n",
    "    # data['Title'] = data['Title'].map(title_mapping)\n",
    "    # data['Title'] = data['Title'].fillna('Other')\n",
    "\n",
    "    # Comprimento do Nome\n",
    "    data['NameLength'] = data['Name'].apply(len)\n",
    "\n",
    "    # Grupos Etários\n",
    "    bins = [0, 12, 18, 30, 50, 200]\n",
    "    labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "    data['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels)\n",
    "    \n",
    "    # Informação sobre Cabine\n",
    "    data['CabinInfo'] = data['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função de preprocessamento nos dados de treino e teste\n",
    "X_train = preprocess_data(train_data.drop(['PassengerId', 'Survived'], axis=1))\n",
    "X_test = preprocess_data(test_data.drop(['PassengerId'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as features categóricas e numéricas\n",
    "categorical_features = ['AgeGroup']\n",
    "numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'IsFemale', 'Port', 'Child', 'FamilySize', 'NameLength', 'CabinInfo']\n",
    "# numeric_features = ['CabinInfo', 'NameLength', 'IsFemale', 'Port', 'Child']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ColumnTransformer com OneHotEncoder para features categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>IsFemale</th>\n",
       "      <th>Port</th>\n",
       "      <th>Child</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>CabinInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Adult</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  IsFemale  Port  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S         0     1   \n",
       "1      1      0          PC 17599  71.2833   C85        C         1     2   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S         1     1   \n",
       "3      1      0            113803  53.1000  C123        S         1     1   \n",
       "4      0      0            373450   8.0500   NaN        S         0     1   \n",
       "\n",
       "   Child  FamilySize  NameLength     AgeGroup  CabinInfo  \n",
       "0      0           1          23  Young Adult          0  \n",
       "1      0           1          51        Adult          1  \n",
       "2      0           0          22  Young Adult          0  \n",
       "3      0           1          44        Adult          1  \n",
       "4      0           0          24        Adult          0  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o ColumnTransformer aos dados de treino e teste\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média dos scores de validação cruzada (Random Forest): 0.8316729088639201\n"
     ]
    }
   ],
   "source": [
    "# Criando e treinando modelo de Random Forest\n",
    "random_forest_model = RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0)\n",
    "cross_val_scores = cross_val_score(random_forest_model, X_train_scaled, y_train, cv=10)\n",
    "\n",
    "# Calculando e imprimindo a média dos scores de validação cruzada\n",
    "print(\"Média dos scores de validação cruzada (Random Forest):\", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores features:\n",
      "                 Feature  Importance\n",
      "10             CabinInfo    0.356867\n",
      "9             NameLength    0.119559\n",
      "14         AgeGroup_Teen    0.105844\n",
      "5               IsFemale    0.093367\n",
      "6                   Port    0.077845\n",
      "15  AgeGroup_Young Adult    0.066974\n",
      "13       AgeGroup_Senior    0.057837\n",
      "7                  Child    0.030595\n",
      "11        AgeGroup_Adult    0.023002\n",
      "1                    Age    0.016609\n",
      "8             FamilySize    0.014961\n",
      "12        AgeGroup_Child    0.014657\n",
      "0                 Pclass    0.008676\n",
      "3                  Parch    0.004445\n",
      "4                   Fare    0.004393\n",
      "2                  SibSp    0.004368\n",
      "['CabinInfo', 'NameLength', 'AgeGroup_Teen', 'IsFemale', 'Port', 'AgeGroup_Young Adult', 'AgeGroup_Senior', 'Child', 'AgeGroup_Adult', 'Age']\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo de Random Forest para calcular a importância das features\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Obtendo a importância das features do modelo\n",
    "feature_importances = random_forest_model.feature_importances_\n",
    "\n",
    "# Criando um DataFrame para mostrar as importâncias das features\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': numeric_features + list(preprocessor.transformers_[0][1].get_feature_names_out(categorical_features)),\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Ordenando as features por importância em ordem decrescente\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Mostrando as melhores features\n",
    "print(\"Melhores features:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Selecionando as top N melhores features (por exemplo, as 8 melhores features)\n",
    "top_features = feature_importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "print(top_features)\n",
    "\n",
    "# Selecionando apenas as melhores features nos conjuntos de treino e teste\n",
    "X_train_selected = X_train_scaled[:, feature_importance_df.index.isin(top_features)]\n",
    "X_test_selected = X_test_scaled[:, feature_importance_df.index.isin(top_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define os espaços de busca para os parâmetros\n",
    "    criterion = trial.suggest_categorical('criterion', ['entropy', 'gini'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "    # Cria o modelo com os parâmetros sugeridos\n",
    "    model_rf_best = RandomForestClassifier(\n",
    "        criterion=criterion,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Avalia o modelo usando validação cruzada\n",
    "    score = cross_val_score(model_rf_best, X_train_scaled, y_train, cv=10)\n",
    "    mean_score = np.mean(score)\n",
    "\n",
    "    return mean_score\n",
    "\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=0))\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Obtém os melhores parâmetros encontrados\n",
    "# best_params = study.best_params\n",
    "# print(\"Melhores parâmetros encontrados:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão (Treino):\n",
      " [[523  26]\n",
      " [ 94 248]]\n",
      "Acurácia nos dados de treino: 0.8653198653198653\n"
     ]
    }
   ],
   "source": [
    "# Criando e treinando modelo de Random Forest\n",
    "random_forest_model_final = RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0)\n",
    "\n",
    "# Treinando o modelo final\n",
    "random_forest_model_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fazendo previsões nos dados de treino\n",
    "y_train_pred = random_forest_model_final.predict(X_train_scaled)\n",
    "\n",
    "# Calculando a matriz de confusão e pontuação nos dados de treino\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Matriz de Confusão (Treino):\\n\", confusion_matrix_train)\n",
    "\n",
    "train_score = random_forest_model_final.score(X_train_scaled, y_train)\n",
    "print(\"Acurácia nos dados de treino:\", train_score)\n",
    "\n",
    "# Fazendo previsões nos dados de teste\n",
    "y_test_pred = random_forest_model_final.predict(X_test_scaled)\n",
    "\n",
    "# Criando DataFrame de submissão\n",
    "submission = pd.DataFrame(test_data['PassengerId'])\n",
    "submission['Survived'] = y_test_pred\n",
    "\n",
    "# Salvando o arquivo de submissão\n",
    "submission.to_csv('submission_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
